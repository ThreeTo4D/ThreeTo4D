<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<!-- saved from url=(0042)https://research.nvidia.com/labs/par/calm/ -->
<html><head><meta http-equiv="Content-Type" content="text/html; charset=windows-1252"><script src="" type="text/javascript"></script>
<script type="text/javascript">google.load("jquery", "1.3.2");</script>
<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script>

<style type="text/css">
body {
    font-family: "Titillium Web", "HelveticaNeue-Light", "Helvetica Neue Light", "Helvetica Neue", Helvetica, Arial, "Lucida Grande", sans-serif;
    font-weight: 300;
    font-size: 17px;
    margin-left: auto;
    margin-right: auto;
    width: 980px;
}
h1 {
    font-weight:300;
    line-height: 1.15em;
}

h2 {
    font-size: 1.75em;
}
a:link,a:visited {
    color: #1367a7;
    text-decoration: none;
}
a:hover {
    color: #208799;
}
h1, h2, h3 {
    text-align: center;
}
h1 {
    font-size: 40px;
    font-weight: 500;
}
h2 {
    font-weight: 400;
    margin: 16px 0px 4px 0px;
}
.paper-title {
    padding: 16px 0px 16px 0px;
}
section {
    margin: 32px 0px 32px 0px;
    text-align: justify;
    clear: both;
}
.col-6 {
     width: 16.6%;
     float: left;
}
.col-5 {
     width: 20%;
     float: left;
}
.col-4 {
     width: 25%;
     float: left;
}
.col-3 {
     width: 33%;
     float: left;
}
.col-2 {
     width: 50%;
     float: left;
}
.row, .author-row, .affil-row {
     overflow: auto;
}
.author-row, .affil-row {
    font-size: 20px;
}
.row {
    margin: 16px 0px 16px 0px;
}
.authors {
    font-size: 18px;
}
.affil-row {
    margin-top: 16px;
}
.teaser {
    max-width: 100%;
}
.text-center {
    text-align: center;  
}
.screenshot {
    width: 256px;
    border: 1px solid #ddd;
}
.screenshot-el {
    margin-bottom: 16px;
}
hr {
    height: 1px;
    border: 0; 
    border-top: 1px solid #ddd;
    margin: 0;
}
.material-icons {
    vertical-align: -6px;
}
p {
    line-height: 1.25em;
}
.caption {
    font-size: 16px;
    /*font-style: italic;*/
    color: #666;
    text-align: left;
    margin-top: 8px;
    margin-bottom: 8px;
}
video {
    display: block;
    margin: auto;
}
figure {
    display: block;
    margin: auto;
    margin-top: 10px;
    margin-bottom: 10px;
}
#bibtex pre {
    font-size: 14px;
    background-color: #eee;
    padding: 16px;
}
.blue {
    color: #2c82c9;
    font-weight: bold;
}
.orange {
    color: #d35400;
    font-weight: bold;
}
.flex-row {
    display: flex;
    flex-flow: row wrap;
    justify-content: space-around;
    padding: 0;
    margin: 0;
    list-style: none;
}
.flex-row-mario {
    display: flex; /* Creates a flex container */
    flex-wrap: nowrap; /* Prevents wrapping to a new line */
    justify-content: space-between; /* Ensures proper spacing */
    align-items: center; /* Align items vertically in the center */
    gap: 10px; /* Adds space between items */
    overflow-x: auto; /* Allows horizontal scrolling if items overflow */
}
.flex-row-teaser {
    display: flex;
    justify-content: center;
    align-items: center;
    gap: 20px; /* Space between GIFs */
    margin-top: 20px;
}
.paper-btn {
  position: relative;
  text-align: center;

  display: inline-block;
  margin: 8px;
  padding: 8px 8px;

  border-width: 0;
  outline: none;
  border-radius: 2px;
  
  background-color: #1367a7;
  color: #ecf0f1 !important;
  font-size: 20px;
  width: 100px;
  font-weight: 600;
}

.supp-btn {
  position: relative;
  text-align: center;

  display: inline-block;
  margin: 8px;
  padding: 8px 8px;

  border-width: 0;
  outline: none;
  border-radius: 2px;
  
  background-color: #1367a7;
  color: #ecf0f1 !important;
  font-size: 20px;
  width: 150px;
  font-weight: 600;
}

.paper-btn-parent {
    display: flex;
    justify-content: center;
    margin: 16px 0px;
}
.paper-btn:hover {
    opacity: 0.85;
}
.container {
    margin-left: auto;
    margin-right: auto;
    padding-left: 16px;
    padding-right: 16px;
}
.venue {
    color: #1367a7;
}

.kitti {
    display: flex;
    justify-content: center;
    margin: 16px 0px;
}

.topnav {
  overflow: hidden;
  background-color: #EEEEEE;
}

.topnav a {
  float: left;
  color: black;
  text-align: center;
  padding: 14px 16px;
  text-decoration: none;
  font-size: 16px;
}

.flex-row {
    display: flex;
    flex-wrap: wrap; /* Ensures videos stack on smaller screens */
    gap: 10px; /* Adds spacing between items */
    justify-content: space-between; /* Adjust spacing between the items */
}

.video-container {
    text-align: center; /* Centers title and video */
    width: calc(25% - 10px); /* Ensures proper spacing with 4 items */
    box-sizing: border-box; /* Includes padding and border in width */
}

.video-container h3 {
    margin-bottom: 4px; /* Smaller spacing between title and image */
    font-size: 12px; /* Adjusted font size */
    line-height: 1.2; /* Better compactness */
}

.video-container img {
    width: 100%; /* Ensure images scale to the container */
    height: auto; /* Maintain aspect ratio */
}

.caption {
    text-align: center; /* Centers the caption */
    font-size: 14px;
    margin-top: 20px;
}

.centered-content {
    text-align: center; /* Centers the text */
}

.centered-content hr {
    width: 50%; /* Adjust the width of the <hr> */
    margin: 0 auto; /* Centers the <hr> */
}


</style>


</head><body><div class="topnav" id="myTopnav">
    <figure style="width: 100%;">
        <a href="./files/Bar-Ilan_University_logo.svg.png">
            <img width="100%" src="./files/Bar-Ilan_University_logo.svg.png">
        </a>
    </figure>
</div>

<!-- End : Google Analytics Code -->
<script type="text/javascript" src="./files/style/hidebib.js"></script>
<link href="./files/style/css" rel="stylesheet" type="text/css">

    <title>Bringing Objects to Life: 4D generation from 3D objects</title>
    <meta property="og:description" content="-Given a set of 3D objects, the task is to find a plausible arrangement of these objects in a scene.">
    <link href="./files/style/css2" rel="stylesheet">

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async="" src="./files/style/js"></script>
<script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());
    gtag('config', 'G-6HHDEXF452');
</script>




 
<div class="container">
    <div class="paper-title">
      <h1>Bringing Objects to Life: 4D generation from 3D objects</h1>
    </div>

    <div id="authors">
        <div class="author-row"></div>
            <div class="col-3 text-center"><a href="https://ohadrahamim.github.io/">Ohad Rahamim</a><sup>1</sup><span>*</span></div>
            <div class="col-3 text-center"><a href="">Ori Malca</a><sup>1</sup><span>*</span></div>
            <div class="col-3 text-center"><a href="https://chechiklab.biu.ac.il/~dvirsamuel/">Dvir Samuel</a><sup>1</sup></div>
            <div class="col-12 text-center"><a href="https://research.nvidia.com/person/gal-chechik">Gal Chechik</a><sup>1,2</sup></div>
        </div>

        <div class="affil-row">
            <div class="venue text-center">
                <span><sup>1</sup>Bar-Ilan University</span>
                <span style="margin: 0 20px;"></span>
                <span><sup>2</sup>NVIDIA</span>
            </div>
        </div>

        <style>
            .equal-contribution-note p {
                font-size: 0.8rem; /* Smaller font size */
                margin: 0; /* Optional: Adjust spacing */
            }
        </style>

        <div class="equal-contribution-note">
            <p><span>*</span> Equal Contribution.</p>
        </div>
        <!-- <div class="affil-row">
            <div class="venue text-center"><b>NeurIPS 2024</b></div>
        </div> -->

        <div style="clear: both">
            <div class="paper-btn-parent">
            <a class="supp-btn" href="">
                <span class="material-icons">  </span> 
                 Paper
            </a>
            <a class="supp-btn" href="">
                <span class="material-icons">  </span> 
                  Code (soon) 
            </a>
        </div></div>
    </div>

    <section id="teaser-videos">
        <div class="flex-row-teaser">
                <!-- <a href="./files/teaser.png">
                    <img width="100%" src="./files/teaser.png">
                </a> -->
                <div class="video-container">
                    <h3 style="font-size: 24px;">3D Mesh</h3>
                    <img src="./processed/elephant-static.gif" alt="Elephant static" width="15%" />
                </div>
                <div class="video-container">
                    <h3 style="font-size: 20px;">"An elephant is shaking its trunk"</h3>
                    <img src="./files/arrow.gif" alt="Mario running" width="15%" />
                </div>
                <div class="video-container">
                    <h3 style="font-size: 24px;">Result 4D</h3>
                    <img src="./processed/An_elephant_shaking_its_trunk.gif" alt="Mario running" width="15%" />
                </div>
            </div>
            <div class="flex-row-teaser">
                <div class="video-container">
                    <h3></h3>
                    <img src="./processed/plant-static.gif" alt="Elephant static" width="15%" />
                </div>
                <div class="video-container">
                    <h3 style="font-size: 20px;">"A plant blooming"</h3>
                    <img src="./files/arrow.gif" alt="Mario running" width="15%" />
                </div>
                <div class="video-container">
                    <h3></h3>
                    <img src="./processed/blooming_plant.gif" alt="Mario running" width="15%" />
                </div>
            </div>
            <p class="caption" style="margin-bottom: 1px;">
                Our method, 3to4D, takes a passive 3D object and a textual prompt  describing a desired action. It then adds dynamics to the object based on the prompt to create a 4D animation, essentially a video viewable from any perspective. On the right, we display four 3D frames from the generated 4D animation.
            </p>
    </section>

    <section id="abstract">
        <h2>Abstract</h2>
        <hr>
        <p>
            Recent advancements in generative models have enabled the creation of dynamic 4D content — 3D objects in motion—based on text prompts,
            which holds potential for applications in virtual worlds, media, and gaming. However, existing methods provide limited control over the 
            appearance of generated content. In this work, we introduce a method for animating user-provided 3D objects by conditioning on textual 
            prompts to guide 4D generation, enabling custom animations while maintaining the original object's identity. We first convert a 3D mesh 
            into a static 4D Neural Radiance Field (NeRF) that preserves the object’s visual attributes. Then, we animate the object using an 
            Image-to-Video diffusion model driven by text. To improve motion realism, we introduce an incremental viewpoint selection protocol for 
            sampling perspectives to promote lifelike movement and a masked Score Distillation Sampling (SDS) loss, which leverages attention maps 
            to focus optimization on relevant regions. We evaluate our model on temporal coherence, prompt adherence, and visual fidelity, and find 
            that our method outperforms baselines based on other approaches, achieving up to threefold improvements in LPIPS scores, and effectively 
            balancing visual quality with dynamic content.
        </p>
    </section>

    <hr>
    <h1>Overview</h1>
    <hr>

    <section id="teaser-videos">
        <div class="flex-row-mario">
            <div class="video-container">
                <h3 style="font-size: 20px;">3D Mesh</h3>
                <img src="./processed/mario-static.gif" alt="Mario static" width="5%" />
            </div>
            <div class="video-container">
                <h3></h3>
                <img src="./files/arrow.gif" alt="Mario static" width="5%" />
            </div>
            <div class="video-container">
                <h3 style="font-size: 20px;">Mario running</h3>
                <img src="./processed/Mario_running.gif" alt="Mario running" width="10%" />
            </div>
            <div class="video-container">
                <h3 style="font-size: 20px;">Mario jumping</h3>
                <img src="./processed/mario_jumping.gif" alt="Mario jumping" width="10%" />
            </div>  
            <div class="video-container">
                <h3 style="font-size: 20px;">Mario waving</h3>
                <img src="./processed/Mario_waving_with_his_hands.gif" alt="Mario jumping" width="10%" />
            </div>  
            <div class="video-container">
                <h3 style="font-size: 20px;">Mario walking</h3>
                <img src="./processed/Mario_walking_with_his_fingers_lifted_in_peace_sign.gif" alt="Mario walking" width="10%" />
            </div>
        </div>
        <p class="caption" style="margin-bottom: 1px;">
            Left: we display the input object. Right: The resulted 4D object viewed from azimuth -60&deg; &#8594; 60&deg;, progressing over time.
        </p>
            <div style="width: 100%;">
                <br><br>
                <p>
                    Instead of generating a 4D dynamic object using text control only, one may want to animate an existing 3D object, 
                    like your favorite 3D toy or character. Conditioning 4D generation on 3D assets offers several advantages: it 
                    enhances control, leverages existing 3D resources efficiently, and accelerates 4D generation by using 3D as a strong 
                    initialization. Despite the availability of extensive, high-quality 3D models, current methods 
                    have not yet used 3D assets to guide 4D generation.
                </p> 

                <p>
                    We introduce a novel method for generating 4D scenes from user-provided 3D representations, called  3to4D, 
                    taking a simple approach that incorporates textual descriptions to govern the animation of the 3D objects.  
                    First, we train a "static" 4D NeRF based on the 3D mesh input, effectively capturing 
                    the object appearance from multiple views, replicated across time. Then, our method modifies 
                    the 4D object using an image-to-video diffusion model, conditioned 
                    the first frame on renderings of the input object.
                </p>

                <p>
                    Unfortunately, we find that applying this approach naively is insufficient, because it dramatically reduces  
                    the level of dynamic motion. To encourage the model to generate more dynamic movements, 
                    we propose two key improvements. First, a new camera viewpoint selector that incrementally samples different 
                    viewpoints around the object during optimization. This gradual-widening sampling approach enhances the 
                    generation process, resulting in more pronounced movement.
                    Second, we introduce a masked variant of the SDS loss, using attention maps obtained from the Image-to-Video model. 
                    This masked SDS focuses the optimization on object-relevant areas of the latent space pixels, enhancing the 
                    optimization of elements related to the object.
                </p>
                
                
            </div>
        </div>
    </section>

    <section id="pipeline">

        <h2>Pipeline</h2>
        <hr>

        <figure style="width: 100%;">
            <a href="./files/pipeline.png">
                <img width="100%" src="./files/pipeline.png">
            </a>
            <p class="caption" style="margin-bottom: 1px;">
                Workflow of our 3to4D, designed to optimize a 4D radiance field using a neural representation that captures both static and dynamic elements. 
                First, a 4D NeRF is trained to represent the passive object (plant, left), having the same input structure at each time step. 
                Then, we introduce dynamics to the 4D NeRF by distilling the prior from a pre-trained image-to-video model. At each SDS step, 
                we select a viewpoint and render both the input object and the 4D NeRF from the same selected viewpoint. These renders, along with the 
                textual prompts, are then fed into the image-to-video model, and the SDS loss is calculated to guide the generation of motion while 
                preserving the object's identity.
                The attention-masked SDS, focuses learning on the relevant parts of the object, improving identity preservation.
            </p>
        </figure>

    </section>    
    
    <section id="Results">

        <h2>Results</h2>
        <div class="centered-content">
            <hr>
            <p>For a collection of 3D objects, we used the Google Scanned Objects (GSO) dataset. This is a collection of high-quality 3D scans of everyday items.</p>
            <hr>
        </div>

        <div class="flex-row">
            <div class="video-container">
                <h3 style="font-size: 20px;">3D Mesh</h3>
                <img src="./processed/hulk-static.gif" alt="Elephant static" width="15%" />
            </div>
            <div class="video-container">
                <h3 style="font-size: 20px;">"the hulk is smashing"</h3>
                <img src="./processed/hulk.gif" alt="Mario running" width="15%" />
            </div>

            <div class="video-container">
                <h3 style="font-size: 20px;">3D Mesh</h3>
                <img src="./processed/plant-static.gif" alt="Elephant static" width="15%" />
            </div>
            <div class="video-container">
                <h3 style="font-size: 20px;">"A plant blooming"</h3>
                <img src="./processed/blooming_plant.gif" alt="Mario running" width="15%" />
            </div>
        </div>

        <div class="flex-row">
            <div class="video-container">
                <h3 style="font-size: 20px;">3D Mesh</h3>
                <img src="./processed/hand_bell-static.gif" alt="Elephant static" width="15%" />
            </div>
            <div class="video-container">
                <h3 style="font-size: 20px;">"A hand bell ringing"</h3>
                <img src="./processed/hand_bell_ringing.gif" alt="Mario running" width="15%" />
            </div>

            <div class="video-container">
                <h3 style="font-size: 20px;">3D Mesh</h3>
                <img src="./processed/Elephant_2-static.gif" alt="Elephant static" width="15%" />
            </div>
            <div class="video-container">
                <h3 style="font-size: 20px;">"An elephant is shaking its hears"</h3>
                <img src="./processed/an_Elephant_shaking_his_hears.gif" alt="Mario running" width="15%" />
            </div>
        </div>

        <div class="flex-row">
            <div class="video-container">
                <h3 style="font-size: 20px;">3D Mesh</h3>
                <img src="./processed/heels-static.gif" alt="Elephant static" width="15%" />
            </div>
            <div class="video-container">
                <h3 style="font-size: 20px;">"A walking heel shoe"</h3>
                <img src="./processed/heels.gif" alt="Mario running" width="15%" />
            </div>

            <div class="video-container">
                <h3 style="font-size: 20px;">3D Mesh</h3>
                <img src="./processed/elephant-static.gif" alt="Elephant static" width="15%" />
            </div>
            <div class="video-container">
                <h3 style="font-size: 19px;">"An elephant is trumpeting with its trunk"</h3>
                <img src="./processed/An_elephant_trumpeting_with_its_trunk.gif" alt="Mario running" width="15%" />
            </div>
        </div>

        <div class="flex-row">
            <div class="video-container">
                <h3 style="font-size: 20px;">3D Mesh</h3>
                <img src="./processed/train-static.gif" alt="Elephant static" width="15%" />
            </div>
            <div class="video-container">
                <h3 style="font-size: 20px;">"Smoke comes out of the train"</h3>
                <img src="./processed/a_smoke_come_out_of_the_train.gif" alt="Mario running" width="15%" />
            </div>

            <div class="video-container">
                <h3 style="font-size: 20px;">3D Mesh</h3>
                <img src="./processed/truck-static.gif" alt="Elephant static" width="15%" />
            </div>
            <div class="video-container">
                <h3 style="font-size: 20px;">"The truck extends its arm to lift the cargo"</h3>
                <img src="./processed/The_truck_extends_its_arm_to_lift_the_cargo.gif" alt="Mario running" width="15%" />
            </div>
        </div>

        <div class="flex-row">
            <div class="video-container">
                <h3 style="font-size: 20px;">3D Mesh</h3>
                <img src="./processed/turtle-static.gif" alt="Elephant static" width="15%" />
            </div>
            <div class="video-container">
                <h3 style="font-size: 20px;">"A turtle has its head inside its shell"</h3>
                <img src="./processed/turtle_head.gif" alt="Mario running" width="15%" />
            </div>

            <div class="video-container">
                <h3 style="font-size: 20px;">3D Mesh</h3>
                <img src="./processed/Honey_dipper-static.gif" alt="Elephant static" width="15%" />
            </div>
            <div class="video-container">
                <h3 style="font-size: 20px;">"A honey dipper drizzle honey"</h3>
                <img src="./processed/honey.gif" alt="Mario running" width="15%" />
            </div>
        </div>
        
            
            <p class="caption" style="margin-bottom: 1px;">
            Example arranged in two columns, where each column has the following structure: 
            On the left, we display the input 3D passive object. On the right, we present a video of generated 4D object, viewed from azimuth -60&deg; &#8594; 60&deg;, progressing over time. 
            The title represnt the input prompt. 
            </p>
        </figure>
        

    </section>
    
    <section id="bibtex">
        <h2>Citation</h2>
        <pre><code>
<!-- @article{rahamim2024lay,
    title={Lay-A-Scene: Personalized 3D Object Arrangement Using Text-to-Image Priors},
    author={Rahamim, Ohad and Segev, Hilit and Achituve, Idan and Atzmon, Yuval and Kasten, Yoni and Chechik, Gal},
    journal={arXiv preprint arXiv:2406.00687},
    year={2024}
    } -->
    </section>

    

<br>


</div>


</body></html>
